{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Laboratorio: Inicio R√°pido con Dataproc (por L√≠nea de Comandos)\n",
        "\n",
        "**Google Cloud Dataproc** es un servicio administrado que permite crear y gestionar cl√∫steres de **Apache Spark** y **Apache Hadoop** en la nube, facilitando el procesamiento de grandes vol√∫menes de datos de manera r√°pida y econ√≥mica. Este laboratorio te guiar√° a trav√©s de la creaci√≥n de un cl√∫ster, la ejecuci√≥n de un trabajo **Spark**, y la modificaci√≥n de la cantidad de nodos, todo desde la l√≠nea de comandos.\n",
        "\n",
        "üí° **Beneficio empresarial**: **Dataproc** permite a las empresas procesar grandes cantidades de datos financieros, como transacciones o auditor√≠as, en minutos, con la capacidad de escalar recursos din√°micamente para optimizar costos y cumplir con normativas.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Google Cloud Dataproc](https://cloud.google.com/dataproc/docs).\n",
        "\n",
        "## üìå Objetivos\n",
        "- ‚úÖ Crear un cl√∫ster de **Dataproc** usando la l√≠nea de comandos.\n",
        "- ‚úÖ Ejecutar un trabajo simple con **Apache Spark**.\n",
        "- ‚úÖ Modificar la cantidad de nodos trabajadores en el cl√∫ster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† ¬øQu√© es Google Cloud Dataproc?\n",
        "\n",
        "- **Dataproc** es un servicio totalmente administrado para crear y gestionar cl√∫steres de **Apache Spark** y **Apache Hadoop**.\n",
        "- Reduce el tiempo de procesamiento de datos de horas o d√≠as a minutos o segundos.\n",
        "- Escalable: permite aumentar o reducir nodos seg√∫n las necesidades de procesamiento.\n",
        "\n",
        "üí° **Contexto empresarial**: **Dataproc** es como un equipo contable automatizado que puede procesar grandes vol√∫menes de transacciones r√°pidamente y ajustarse al tama√±o del trabajo, pagando solo por los recursos utilizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Comandos √∫tiles (opcional)\n",
        "\n",
        "Antes de comenzar, puedes verificar la configuraci√≥n de tu entorno:\n",
        "\n",
        "1. Lista la cuenta activa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud auth list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Muestra la cuenta activa (marcada con un asterisco `*`).\n",
        "\n",
        "2. Muestra el ID del proyecto activo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud config list project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Confirma el proyecto activo en **Cloud Shell**.\n",
        "\n",
        "üí° **Contexto empresarial**: Estos comandos son como verificar las credenciales y el proyecto contable antes de procesar datos financieros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Tarea 1: Crear un cl√∫ster Dataproc\n",
        "\n",
        "En esta tarea, crear√°s un cl√∫ster de **Dataproc** desde **Cloud Shell**.\n",
        "\n",
        "### Paso 1.1: Establecer la regi√≥n\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud config set dataproc/region REGION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Define la regi√≥n donde se crear√° el cl√∫ster (reemplaza `REGION` con, por ejemplo, `us-central1`).\n",
        "- La regi√≥n agrupa recursos geogr√°ficamente para mejorar la eficiencia y cumplir con normativas.\n",
        "\n",
        "üí° **Contexto empresarial**: Esto es como elegir la sucursal donde operar√° un equipo contable, optimizando la latencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1.2: Obtener el ID y n√∫mero del proyecto\n",
        "\n",
        "1. Guarda el ID del proyecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PROJECT_ID=$(gcloud config get-value project) && \\\n",
        "gcloud config set project $PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Guarda el ID del proyecto en la variable `PROJECT_ID` y lo establece como activo.\n",
        "\n",
        "2. Guarda el n√∫mero del proyecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PROJECT_NUMBER=$(gcloud projects describe $PROJECT_ID --format='value(projectNumber)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Obtiene el n√∫mero del proyecto (diferente del ID) para usarlo en la configuraci√≥n de permisos.\n",
        "\n",
        "üí° **Contexto empresarial**: Esto es como confirmar los detalles de la empresa antes de configurar un sistema contable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1.3: Otorgar permisos de almacenamiento al servicio\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
        "  --member=serviceAccount:$PROJECT_NUMBER-compute@developer.gserviceaccount.com \\\n",
        "  --role=roles/storage.admin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Otorga el rol **Storage Admin** a la cuenta de servicio de **Compute Engine**, permitiendo al cl√∫ster leer y escribir en **Cloud Storage**.\n",
        "\n",
        "üí° **Contexto empresarial**: Esto es como dar permisos a un equipo contable para acceder a un archivo digital de registros financieros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1.4: Habilitar acceso privado a Google\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud compute networks subnets update default --region=REGION --enable-private-ip-google-access"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Habilita el acceso privado a servicios de Google (como **Cloud Storage**) sin usar IPs p√∫blicas, aumentando la seguridad.\n",
        "\n",
        "üí° **Contexto empresarial**: Esto es como configurar una red interna segura para que el equipo contable acceda a documentos sin exponerlos al exterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1.5: Crear el cl√∫ster\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud dataproc clusters create example-cluster \\\n",
        "  --worker-boot-disk-size 500 \\\n",
        "  --worker-machine-type=e2-standard-4 \\\n",
        "  --master-machine-type=e2-standard-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Desglose del comando**:\n",
        "| **Parte** | **Significado** |\n",
        "|-----------|-----------------|\n",
        "| `gcloud dataproc clusters create` | Crea un cl√∫ster **Dataproc**. |\n",
        "| `example-cluster` | Nombre del cl√∫ster. |\n",
        "| `--worker-boot-disk-size 500` | Tama√±o del disco de cada nodo trabajador (500 GB). |\n",
        "| `--worker-machine-type=e2-standard-4` | Tipo de m√°quina para los nodos trabajadores (balanceada en precio/rendimiento). |\n",
        "| `--master-machine-type=e2-standard-4` | Tipo de m√°quina para el nodo maestro. |\n",
        "\n",
        "**Resultado esperado**:\n",
        "- El cl√∫ster se crea tras unos minutos, mostrando: `Created [... example-cluster]`.\n",
        "\n",
        "**Explicaci√≥n**:\n",
        "- El cl√∫ster incluye un nodo maestro (coordinador) y nodos trabajadores que ejecutan tareas de **Spark** o **Hadoop**.\n",
        "\n",
        "üí° **Contexto empresarial**: Crear un cl√∫ster es como formar un equipo contable automatizado, con un l√≠der (maestro) y trabajadores que procesan datos financieros en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Tarea 2: Ejecutar un trabajo Spark\n",
        "\n",
        "En esta tarea, enviar√°s un trabajo **Spark** para calcular el valor de œÄ usando el m√©todo Monte Carlo.\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud dataproc jobs submit spark --cluster example-cluster \\\n",
        "  --class org.apache.spark.examples.SparkPi \\\n",
        "  --jars file:///usr/lib/spark/examples/jars/spark-examples.jar -- 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Desglose del comando**:\n",
        "| **Parte** | **Significado** |\n",
        "|-----------|-----------------|\n",
        "| `gcloud dataproc jobs submit spark` | Env√≠a un trabajo de tipo **Spark**. |\n",
        "| `--cluster example-cluster` | Especifica el cl√∫ster donde se ejecuta. |\n",
        "| `--class org.apache.spark.examples.SparkPi` | Clase Java que calcula œÄ. |\n",
        "| `--jars file:///usr/lib/spark/...` | Ruta al archivo JAR que contiene el c√≥digo. |\n",
        "| `-- 1000` | N√∫mero de iteraciones (puntos aleatorios) para el c√°lculo. |\n",
        "\n",
        "**Resultado esperado**:\n",
        "- La salida muestra: `Pi is roughly 3.14118528`.\n",
        "\n",
        "**Explicaci√≥n**:\n",
        "- El trabajo **SparkPi** usa el m√©todo Monte Carlo, generando 1000 puntos aleatorios para aproximar œÄ. **Spark** distribuye el c√°lculo entre los nodos trabajadores.\n",
        "\n",
        "üí° **Contexto empresarial**: Enviar un trabajo **Spark** es como asignar un c√°lculo financiero (por ejemplo, un indicador de rentabilidad) a un equipo contable que lo procesa en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Tarea 3: Actualizar el cl√∫ster\n",
        "\n",
        "En esta tarea, escalar√°s el cl√∫ster para ajustar su capacidad de procesamiento.\n",
        "\n",
        "### Paso 3.1: Aumentar la cantidad de nodos trabajadores\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud dataproc clusters update example-cluster --num-workers 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Cambia el n√∫mero de nodos trabajadores a 4, aumentando la capacidad de procesamiento.\n",
        "\n",
        "üí° **Contexto empresarial**: Esto es como contratar m√°s contadores durante un cierre fiscal para acelerar el procesamiento de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 3.2: Reducir la cantidad de nodos\n",
        "\n",
        "1. Ejecuta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gcloud dataproc clusters update example-cluster --num-workers 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explicaci√≥n**:\n",
        "- Reduce los nodos trabajadores a 2, optimizando costos cuando la carga de trabajo es menor.\n",
        "\n",
        "üí° **Contexto empresarial**: Esto es como reducir el equipo contable una vez finalizado un proyecto intensivo, ahorrando recursos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Tarea 4: Evaluaci√≥n de comprensi√≥n\n",
        "\n",
        "| **Pregunta** | **Respuesta** |\n",
        "|--------------|---------------|\n",
        "| ¬øLos cl√∫steres pueden escalarse r√°pidamente usando distintos tipos de m√°quinas, discos y nodos? | ‚úÖ S√≠ (True) |\n",
        "\n",
        "## üöÄ Resumen\n",
        "\n",
        "| **Concepto** | **Explicaci√≥n contable simplificada** |\n",
        "|--------------|--------------------------------------|\n",
        "| **Dataproc** | Sistema automatizado para procesar grandes vol√∫menes de datos financieros, como transacciones o auditor√≠as. |\n",
        "| **Cl√∫ster** | Equipo contable digital con un l√≠der (nodo maestro) y trabajadores (nodos) que procesan datos en paralelo. |\n",
        "| **Spark** | Herramienta que distribuye c√°lculos financieros entre m√∫ltiples m√°quinas para mayor rapidez. |\n",
        "| **Escalabilidad** | Capacidad de ajustar el tama√±o del equipo contable seg√∫n la carga de trabajo, optimizando costos. |\n",
        "\n",
        "üí° **Conclusi√≥n empresarial**: **Dataproc** permite a las empresas procesar datos financieros masivos de forma r√°pida y escalable, con la flexibilidad de ajustar recursos din√°micamente. Esto reduce costos operativos, acelera an√°lisis y asegura cumplimiento normativo, ideal para cierres fiscales o auditor√≠as masivas.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Google Cloud Dataproc](https://cloud.google.com/dataproc/docs)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Bash",
      "language": "bash",
      "name": "bash"
    },
    "language_info": {
      "name": "bash"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}