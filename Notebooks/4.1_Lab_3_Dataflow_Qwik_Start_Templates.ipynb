{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìå Laboratorio: Dataflow Qwik Start - Templates\n",
        "\n",
        "## üéØ Objetivo General\n",
        "Este laboratorio muestra c√≥mo usar una plantilla predefinida de **Dataflow** para recibir datos en tiempo real desde **Pub/Sub**, procesarlos autom√°ticamente y almacenarlos en una tabla de **BigQuery**. \n",
        "\n",
        "üí° **Contexto empresarial**: Similar a una caja registradora digital que registra transacciones en tiempo real y las carga autom√°ticamente a un libro contable digital, optimizando procesos financieros sin intervenci√≥n manual.\n",
        "\n",
        "### Objetivos del Laboratorio\n",
        "- Activar la **Dataflow API**.\n",
        "- Crear un **dataset** y una tabla en **BigQuery**, y un **bucket** en **Cloud Storage**.\n",
        "- Ejecutar un pipeline de **Dataflow** usando una plantilla.\n",
        "- Consultar los datos procesados en **BigQuery**.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Dataflow](https://cloud.google.com/dataflow/docs), [Documentaci√≥n de BigQuery](https://cloud.google.com/bigquery/docs), y [Documentaci√≥n de Pub/Sub](https://cloud.google.com/pubsub/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Tarea 1: Activar y Reiniciar la API de Dataflow\n",
        "\n",
        "### Pasos\n",
        "1. En la consola de **Google Cloud**, busca **Dataflow API** en la barra superior.\n",
        "2. Haz clic en **Dataflow API** > **Manage**.\n",
        "3. Selecciona **Disable API** y confirma.\n",
        "4. Luego, haz clic en **Enable** para reactivar la API.\n",
        "\n",
        "üí° **Prop√≥sito**: Reiniciar la API asegura que el servicio est√© correctamente configurado, como verificar que un sistema contable est√© listo antes de procesar transacciones.\n",
        "\n",
        "üí° **Beneficio empresarial**: Garantiza que el pipeline funcione sin errores, similar a validar un software contable antes de usarlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Tarea 2: Crear Dataset, Tabla y Bucket\n",
        "\n",
        "### Crear un Dataset en BigQuery\n",
        "Crea un dataset llamado `taxirides` para almacenar datos de viajes:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "bq mk taxirides",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üí° **Prop√≥sito**: El dataset es como un libro contable digital que organiza los registros de viajes.\n",
        "\n",
        "üí° **Analog√≠a contable**: Similar a crear un nuevo archivo para registrar transacciones financieras.\n",
        "\n",
        "### Crear una Tabla en BigQuery\n",
        "Crea una tabla `realtime` en el dataset `taxirides` con un esquema espec√≠fico:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "bq mk \\\n  --time_partitioning_field timestamp \\\n  --schema ride_id:string,point_idx:integer,latitude:float,longitude:float,timestamp:timestamp,meter_reading:float,meter_increment:float,ride_status:string,passenger_count:integer \\\n  -t taxirides.realtime",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Parte del Comando | Qu√© Hace (Analog√≠a Contable) |\n",
        "|-------------------|-----------------------------|\n",
        "| `--time_partitioning_field timestamp` | Divide los datos por fecha y hora, como organizar un libro contable por d√≠as. |\n",
        "| `--schema ...` | Define las columnas (ej. `ride_id`, `timestamp`), como las columnas de un registro financiero. |\n",
        "| `-t taxirides.realtime` | Especifica la tabla `realtime` en el dataset `taxirides`. |\n",
        "\n",
        "üí° **Prop√≥sito**: Define la estructura para almacenar datos de viajes, como configurar un libro diario con columnas para transacciones.\n",
        "\n",
        "üí° **Beneficio empresarial**: Permite consultas r√°pidas y organizadas, ideal para reportes financieros o auditor√≠as.\n",
        "\n",
        "### Crear un Bucket en Cloud Storage\n",
        "1. Define el nombre del bucket (usa el **Project ID** o un nombre √∫nico):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "export BUCKET_NAME=\"NombreDelBucket\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Crea el bucket:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "gsutil mb gs://$BUCKET_NAME/",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üí° **Prop√≥sito**: El bucket act√∫a como una carpeta temporal para archivos intermedios, como un archivador para documentos financieros antes de registrarlos.\n",
        "\n",
        "üí° **Beneficio empresarial**: Proporciona almacenamiento escalable y seguro para datos en tr√°nsito.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de BigQuery](https://cloud.google.com/bigquery/docs) y [Documentaci√≥n de Cloud Storage](https://cloud.google.com/storage/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñ±Ô∏è Tarea 3: Alternativa Gr√°fica (Opcional)\n",
        "\n",
        "Si prefieres la interfaz web, puedes crear el dataset, la tabla y el bucket desde la consola de **Google Cloud**:\n",
        "1. **BigQuery**: Ve a **BigQuery > Create Dataset**, configura `taxirides`, y crea la tabla `realtime` con el esquema especificado.\n",
        "2. **Cloud Storage**: Ve a **Cloud Storage > Buckets > Create**, especifica el nombre del bucket.\n",
        "\n",
        "üí° **Nota**: Omit√≠ esta tarea si realizaste la Tarea 2 con comandos en **Cloud Shell**.\n",
        "\n",
        "üí° **Contexto empresarial**: Usar la interfaz web es como configurar un sistema contable manualmente, mientras que los comandos automatizan el proceso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Tarea 4: Ejecutar el Pipeline con Dataflow\n",
        "\n",
        "Ejecuta un pipeline usando una plantilla predefinida para conectar **Pub/Sub** a **BigQuery** (reemplaza `Region`, `Bucket Name`, y `ProjectID` con valores espec√≠ficos, ej. `us-central1`, `my-project-bucket`, `my-project-id`):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "gcloud dataflow jobs run iotflow \\\n  --gcs-location gs://dataflow-templates-Region/latest/PubSub_to_BigQuery \\\n  --region Region \\\n  --worker-machine-type e2-medium \\\n  --staging-location gs://Bucket_Name/temp \\\n  --parameters inputTopic=projects/pubsub-public-data/topics/taxirides-realtime,outputTableSpec=ProjectID:taxirides.realtime",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Elemento | Descripci√≥n |\n",
        "|----------|-------------|\n",
        "| `gcloud dataflow jobs run` | Ejecuta un trabajo en **Dataflow**. |\n",
        "| `iotflow` | Nombre del trabajo. |\n",
        "| `--gcs-location` | Ruta a la plantilla **PubSub_to_BigQuery**. |\n",
        "| `--region` | Regi√≥n donde se ejecuta el pipeline. |\n",
        "| `--worker-machine-type` | Tipo de m√°quina para el procesamiento. |\n",
        "| `--staging-location` | Bucket para archivos temporales. |\n",
        "| `--parameters` | Define la fuente (**Pub/Sub**) y destino (**BigQuery**). |\n",
        "\n",
        "üí° **Prop√≥sito**: Configura un flujo automatizado que procesa datos en tiempo real desde **Pub/Sub** y los carga en **BigQuery**.\n",
        "\n",
        "üí° **Analog√≠a contable**: Como un sistema que registra transacciones de una caja registradora en tiempo real y las carga directamente al libro contable.\n",
        "\n",
        "üí° **Beneficio empresarial**: Automatiza la captura y procesamiento de datos financieros, reduciendo errores y acelerando reportes.\n",
        "\n",
        "Para monitorear, ve a **Google Cloud Console > Dataflow > Jobs**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Tarea 5: Consultar los Datos en BigQuery\n",
        "\n",
        "Consulta los datos cargados en la tabla `realtime`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "SELECT * FROM `ProjectID.taxirides.realtime` LIMIT 1000",
      "language": "sql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üí° **Prop√≥sito**: Recupera los √∫ltimos 1000 registros de viajes, como revisar los √∫ltimos comprobantes financieros en un sistema contable.\n",
        "\n",
        "üí° **Beneficio empresarial**: Permite analizar datos en tiempo real para reportes financieros o auditor√≠as r√°pidas.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de BigQuery](https://cloud.google.com/bigquery/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìò Tarea 6: Evaluaci√≥n Final\n",
        "\n",
        "1. **¬øDataflow permite procesamiento por lotes?**\n",
        "   - ‚úÖ **Verdadero** ‚Äî Soporta **batch** y **streaming**.\n",
        "\n",
        "2. **¬øQu√© plantilla se us√≥ para ejecutar el pipeline?**\n",
        "   - ‚úÖ **Pub/Sub to BigQuery**\n",
        "\n",
        "üí° **Contexto empresarial**: Estas preguntas refuerzan la comprensi√≥n de **Dataflow** como una herramienta para automatizar procesos contables en tiempo real o por lotes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Cuadro Resumen Final\n",
        "\n",
        "| Elemento | Descripci√≥n |\n",
        "|----------|-------------|\n",
        "| **Dataflow API** | Servicio para automatizar procesamiento ETL en tiempo real o por lotes. |\n",
        "| **BigQuery dataset y tabla** | Estructura para guardar y consultar datos, como libros contables digitales. |\n",
        "| **Cloud Storage bucket** | Almacenamiento temporal para archivos en tr√°nsito. |\n",
        "| **Pub/Sub** | Sistema de mensajer√≠a en tiempo real, como una caja registradora. |\n",
        "| **Pipeline** | Flujo automatizado que extrae, transforma y carga datos en **BigQuery**. |\n",
        "| **Comando bq mk** | Crea datasets y tablas, definiendo su estructura. |\n",
        "| **Plantilla Dataflow** | **Pub/Sub to BigQuery** para datos en tiempo real. |\n",
        "| **Consulta SQL** | `SELECT * FROM taxirides.realtime LIMIT 1000` para revisar registros. |\n",
        "\n",
        "üí° **Conclusi√≥n empresarial**: Este laboratorio automatiza la captura y an√°lisis de datos en tiempo real, ideal para procesar transacciones financieras y generar reportes instant√°neos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Conclusi√≥n\n",
        "\n",
        "Este laboratorio te permiti√≥:\n",
        "1. Activar la **Dataflow API**.\n",
        "2. Crear un **dataset** y tabla en **BigQuery**, y un **bucket** en **Cloud Storage**.\n",
        "3. Ejecutar un pipeline de **Dataflow** con la plantilla **Pub/Sub to BigQuery**.\n",
        "4. Consultar datos procesados en **BigQuery**.\n",
        "\n",
        "üí° **Beneficio empresarial**: Automatiza procesos ETL para datos financieros, como registrar transacciones en tiempo real, optimizando eficiencia y reduciendo errores.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Dataflow](https://cloud.google.com/dataflow/docs), [Documentaci√≥n de BigQuery](https://cloud.google.com/bigquery/docs), [Documentaci√≥n de Pub/Sub](https://cloud.google.com/pubsub/docs), y [Documentaci√≥n de Cloud Storage](https://cloud.google.com/storage/docs)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Bash",
      "language": "bash",
      "name": "bash"
    },
    "language_info": {
      "name": "bash"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}