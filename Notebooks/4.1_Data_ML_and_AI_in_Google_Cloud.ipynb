{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìå Servicios Gestionados de Big Data en la Nube\n",
        "\n",
        "## üåê Introducci√≥n a Big Data\n",
        "**Big Data** se refiere al manejo de grandes vol√∫menes de datos que superan las capacidades de herramientas tradicionales. En la actualidad, las empresas han pasado de usar **terabytes (TB)** a **petabytes (PB)** como unidad est√°ndar.\n",
        "\n",
        "### ¬øQu√© es un Petabyte?\n",
        "- **1 PB** = 1,000 TB = 1,000,000 GB.\n",
        "- **Ejemplos ilustrativos**:\n",
        "  - Equivale a una pila de disquetes m√°s alta que 12 edificios Empire State.\n",
        "  - Descargarlo por 4G tomar√≠a ~27 a√±os.\n",
        "  - Almacena todos los tweets hist√≥ricos multiplicados por 50.\n",
        "- **Perspectiva**:\n",
        "  - Solo guarda 2 microgramos de ADN.\n",
        "  - Equivale a un d√≠a de contenido subido a YouTube.\n",
        "\n",
        "üí° **Contexto empresarial**: En contabilidad, un petabyte puede almacenar millones de transacciones financieras, facturas y registros hist√≥ricos, permitiendo an√°lisis profundos para auditor√≠as o proyecciones.\n",
        "\n",
        "### Importancia del Big Data\n",
        "- **Objetivo**: No solo almacenar datos, sino extraer informaci√≥n √∫til para mejorar operaciones.\n",
        "- **Beneficio**: Identificar patrones, optimizar procesos y tomar decisiones estrat√©gicas.\n",
        "\n",
        "üí° **Ejemplo contable**: Analizar transacciones de clientes para detectar tendencias de gasto o riesgos financieros.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Google Cloud Big Data](https://cloud.google.com/solutions/big-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Servicios Gestionados de Big Data en Google Cloud\n",
        "\n",
        "**Google Cloud** ofrece herramientas gestionadas para procesar **Big Data** sin preocuparte por la infraestructura t√©cnica. Los servicios clave son:\n",
        "\n",
        "1. **Dataproc**: Procesamiento con **Apache Hadoop** y **Apache Spark**.\n",
        "2. **Dataflow**: Procesamiento en streaming y por lotes (**batch**).\n",
        "3. **BigQuery**: An√°lisis de datos a escala petabyte con **SQL**.\n",
        "\n",
        "| Servicio | Uso Principal | Caracter√≠sticas | Casos Comunes |\n",
        "|---------|---------------|-----------------|---------------|\n",
        "| **Dataproc** | Procesamiento con Hadoop/Spark | Usa herramientas open source; f√°cil migraci√≥n | Empresas con sistemas legados |\n",
        "| **Dataflow** | Streaming y batch | Maneja datos estructurados/no estructurados en tiempo real | Sensores, redes sociales, logs |\n",
        "| **BigQuery** | An√°lisis a gran escala | Consultas SQL r√°pidas; soporta petabytes | Reportes BI, dashboards, KPIs |\n",
        "\n",
        "üí° **Beneficio empresarial**: Automatizar procesos contables, como consolidar datos financieros de m√∫ltiples fuentes o generar reportes en tiempo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Introducci√≥n a Dataproc: Procesamiento de Grandes Vol√∫menes\n",
        "\n",
        "### ¬øQu√© es Dataproc?\n",
        "**Dataproc** es un servicio gestionado que permite ejecutar **Apache Hadoop** y **Apache Spark** para procesar grandes vol√∫menes de datos.\n",
        "\n",
        "üí° **Analog√≠a contable**: Como un equipo automatizado que analiza y consolida libros contables digitales r√°pidamente, sin necesidad de mantener servidores encendidos.\n",
        "\n",
        "### Tecnolog√≠as Base\n",
        "- **Apache Hadoop**: Conjunto de herramientas para procesar datos en m√∫ltiples computadoras.\n",
        "- **Apache Spark**: Motor r√°pido para an√°lisis por lotes y en tiempo real.\n",
        "\n",
        "### Caracter√≠sticas Clave\n",
        "1. **Costo efectivo**: Desde 1 centavo por vCPU/hora + recursos usados.\n",
        "2. **R√°pido y escalable**: Clusters en <90 segundos.\n",
        "3. **Open source**: Compatible con Spark, Hadoop, Pig, Hive.\n",
        "4. **Gestionado**: Sin necesidad de administrar servidores.\n",
        "5. **Versionado**: Opciones de versiones de Spark/Hadoop.\n",
        "6. **Integraci√≥n**: Con **Cloud Storage**, **BigQuery**, **Bigtable**, **Cloud Logging**, **Cloud Monitoring**.\n",
        "\n",
        "### Ejemplo de Comando\n",
        "Crear un cluster en **Dataproc**:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "gcloud dataproc clusters create my-cluster \\\n    --region=REGION \\\n    --zone=ZONE \\\n    --image-version=2.0-debian10 \\\n    --master-machine-type=e2-standard-4 \\\n    --worker-machine-type=e2-standard-4 \\\n    --num-workers=2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üí° **Prop√≥sito**: Crea un cluster para procesar datos, como consolidar transacciones financieras de m√∫ltiples sucursales.\n",
        "\n",
        "### Casos de Uso\n",
        "- **Logs diarios**: Procesar 50 GB de logs en minutos.\n",
        "- **An√°lisis con Spark**: Escalar an√°lisis sin intervenci√≥n t√©cnica.\n",
        "- **Machine Learning**: Clasificar datos con **Spark MLlib**.\n",
        "\n",
        "| Elemento | Descripci√≥n |\n",
        "|----------|-------------|\n",
        "| **Servicio** | Dataproc |\n",
        "| **Tecnolog√≠as** | Hadoop, Spark |\n",
        "| **Uso** | Procesamiento batch, streaming, ML |\n",
        "| **Costo** | Desde 1 centavo/vCPU/hora |\n",
        "| **Ventajas** | R√°pido, escalable, gestionado |\n",
        "| **Casos** | Logs, an√°lisis Spark, MLlib |\n",
        "| **Analog√≠a contable** | Oficina temporal de an√°lisis financiero |\n",
        "| **Integraciones** | Cloud Storage, BigQuery, Bigtable, Logging, Monitoring |\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Dataproc](https://cloud.google.com/dataproc/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Introducci√≥n a Dataflow: Procesamiento de Datos\n",
        "\n",
        "### ¬øQu√© es Dataflow?\n",
        "**Dataflow** es un servicio gestionado para procesos **ETL** (Extract, Transform, Load) en streaming o por lotes.\n",
        "\n",
        "üí° **Analog√≠a contable**: Automatiza la recolecci√≥n, limpieza y carga de datos financieros, como procesar facturas electr√≥nicas en tiempo real.\n",
        "\n",
        "### Diferencia con Dataproc\n",
        "- **Dataproc**: Ideal para sistemas legados (Hadoop/Spark).\n",
        "- **Dataflow**: Optimizado para pipelines modernos, sin depender de Hadoop.\n",
        "\n",
        "### Caracter√≠sticas\n",
        "- **Pipelines**: Secuencias automatizadas para ETL.\n",
        "- **Escalabilidad**: Recursos asignados a demanda.\n",
        "- **Tolerancia a fallos**: Resultados correctos siempre.\n",
        "- **Monitoreo**: M√©tricas en tiempo real (rendimiento, lag).\n",
        "- **Integraci√≥n**: Con **Cloud Storage**, **Pub/Sub**, **Datastore**, **Bigtable**, **BigQuery**.\n",
        "\n",
        "### Ejemplo de Pipeline\n",
        "Pipeline b√°sico en Python con **Apache Beam** para contar palabras:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import apache_beam as beam\n\ndef run():\n    with beam.Pipeline() as pipeline:\n        (\n            pipeline\n            | 'Read' >> beam.io.ReadFromText('gs://my-bucket/input.txt')\n            | 'Split' >> beam.FlatMap(lambda x: x.split())\n            | 'Count' >> beam.combiners.Count.PerElement()\n            | 'Write' >> beam.io.WriteToText('gs://my-bucket/output.txt')\n        )\n\nif __name__ == '__main__':\n    run()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üí° **Prop√≥sito**: Procesa datos de un archivo en **Cloud Storage**, como contar transacciones por categor√≠a.\n",
        "\n",
        "| Concepto | Descripci√≥n |\n",
        "|----------|-------------|\n",
        "| **Dataflow** | Servicio para pipelines ETL |\n",
        "| **ETL** | Extraer, transformar, cargar |\n",
        "| **Batch/Streaming** | Procesamiento hist√≥rico o en tiempo real |\n",
        "| **Ventajas** | Escalabilidad, tolerancia a fallos, monitoreo |\n",
        "| **Integraciones** | Cloud Storage, Pub/Sub, BigQuery, Bigtable |\n",
        "| **Analog√≠a contable** | Automatizar an√°lisis de facturas |\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Dataflow](https://cloud.google.com/dataflow/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Introducci√≥n a BigQuery: An√°lisis de Datos\n",
        "\n",
        "### ¬øQu√© es BigQuery?\n",
        "**BigQuery** es un **data warehouse** serverless para an√°lisis de datos a escala petabyte, usando **SQL**.\n",
        "\n",
        "üí° **Analog√≠a contable**: Como un archivo centralizado que consolida datos de ventas, compras y gastos para generar reportes financieros.\n",
        "\n",
        "### Caracter√≠sticas\n",
        "1. **Almacenamiento y an√°lisis**: Petabytes de datos con herramientas de **ML**, geoespacial y **BI**.\n",
        "2. **Serverless**: Sin gesti√≥n de infraestructura.\n",
        "3. **Precios flexibles**: Pago por uso o tarifa fija.\n",
        "4. **Seguridad**: Encriptaci√≥n autom√°tica.\n",
        "5. **BigQuery ML**: Modelos de machine learning con **SQL**.\n",
        "\n",
        "### Ejemplo de Consulta\n",
        "Consulta SQL para analizar ventas por regi√≥n:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "SELECT region, SUM(sales_amount) as total_sales\nFROM `my-project.dataset.sales`\nGROUP BY region\nORDER BY total_sales DESC;",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üí° **Prop√≥sito**: Resume ventas por regi√≥n, √∫til para reportes financieros.\n",
        "\n",
        "### Arquitectura\n",
        "- **Ingesta**:\n",
        "  - **Streaming**: Via **Pub/Sub**.\n",
        "  - **Batch**: Desde **Cloud Storage**.\n",
        "  - **ETL**: Procesado con **Dataflow**.\n",
        "- **Destinos**: **Looker**, **Looker Studio**, **Google Sheets**, **Vertex AI**.\n",
        "\n",
        "| Concepto | Explicaci√≥n |\n",
        "|----------|-------------|\n",
        "| **BigQuery** | Data warehouse serverless |\n",
        "| **Data Warehouse** | Archivo central de datos |\n",
        "| **Serverless** | Sin gesti√≥n de servidores |\n",
        "| **SQL** | Lenguaje para consultas |\n",
        "| **ETL** | Extraer, transformar, cargar |\n",
        "| **BigQuery ML** | ML con SQL |\n",
        "| **BI Tools** | Looker, Tableau, Google Sheets |\n",
        "| **Analog√≠a contable** | Archivo contable consolidado |\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de BigQuery](https://cloud.google.com/bigquery/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Conclusi√≥n\n",
        "\n",
        "Este m√≥dulo te permiti√≥:\n",
        "1. Comprender **Big Data** y su importancia empresarial.\n",
        "2. Explorar **Dataproc** para Hadoop/Spark.\n",
        "3. Conocer **Dataflow** para pipelines ETL.\n",
        "4. Usar **BigQuery** para an√°lisis a gran escala.\n",
        "\n",
        "üí° **Beneficio empresarial**: Automatizar y escalar procesos contables, desde consolidar transacciones hasta generar reportes predictivos.\n",
        "\n",
        "Para m√°s informaci√≥n, consulta la [Documentaci√≥n de Google Cloud Big Data](https://cloud.google.com/solutions/big-data)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}